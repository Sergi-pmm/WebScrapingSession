{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping: CNMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Scraping de la CNMV\n",
    "\n",
    "### ¬øQu√© es la CNMV?\n",
    "\n",
    "La **Comisi√≥n Nacional del Mercado de Valores** (cnmv.es) supervisa los mercados financieros en Espa√±a. Su web contiene registros p√∫blicos con informaci√≥n sobre:\n",
    "\n",
    "- Sociedades y Agencias de Valores registradas\n",
    "- Empresas de Asesoramiento Financiero\n",
    "- Entidades advertidas (\"chiringuitos financieros\")\n",
    "- Hechos relevantes de empresas cotizadas\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "Vamos a extraer el **listado de Sociedades y Agencias de Valores** registradas en la CNMV, obteniendo:\n",
    "- Nombre de la entidad\n",
    "- N√∫mero de registro\n",
    "- Fecha de registro\n",
    "- Direcci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Descargar la p√°gina del listado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL del listado de Sociedades y Agencias de Valores\n",
    "url_cnmv = \"https://www.cnmv.es/portal/consultas/listadoentidad?id=1&tipoent=0&lang=es\"\n",
    "\n",
    "# La CNMV necesita headers para responder correctamente\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\",\n",
    "    \"Accept-Language\": \"es-ES,es;q=0.9\",\n",
    "}\n",
    "\n",
    "respuesta = requests.get(url_cnmv, headers=headers)\n",
    "print(f\"Status code: {respuesta.status_code}\")\n",
    "print(f\"Tama√±o: {len(respuesta.text):,} caracteres\") # Las {} son marcadores de expresi√≥n dentro del f-string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(respuesta.text, \"html.parser\")\n",
    "\n",
    "# Confirmamos que llegamos a la p√°gina correcta\n",
    "titulo = soup.find(\"h1\")\n",
    "if titulo:\n",
    "    print(\"P√°gina:\", titulo.text.strip())\n",
    "else:\n",
    "    print(\"T√≠tulo de la p√°gina:\", soup.title.text.strip() if soup.title else \"no encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Analizar la estructura HTML\n",
    "\n",
    "Antes de extraer datos, necesitamos **inspeccionar** el HTML para entender c√≥mo est√°n organizados.\n",
    "\n",
    "> En tu navegador, haz clic derecho sobre un nombre de entidad ‚Üí \"Inspeccionar\" para ver los tags HTML.\n",
    "\n",
    "La p√°gina de la CNMV tiene bloques repetidos con esta estructura:\n",
    "```\n",
    "NOMBRE DE LA ENTIDAD\n",
    "N√∫mero y fecha de registro oficial: 251 - 29/08/2013\n",
    "Direcci√≥n: CALLE TAL, N¬∫ X - C√ìDIGO CIUDAD\n",
    "```\n",
    "\n",
    "Vamos a buscar los elementos que contienen esta informaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscamos el contenedor principal del contenido\n",
    "# La CNMV usa ASP.NET, el contenido suele estar en un div con id \"maincontent\" o similar\n",
    "main = soup.find(\"div\", id=\"maincontent\") or soup.find(\"main\") or soup\n",
    "\n",
    "# Exploramos: buscamos todos los textos que contengan \"N√∫mero y fecha de registro\"\n",
    "# Esto nos ayuda a localizar los bloques de entidades\n",
    "textos_registro = main.find_all(string=re.compile(r\"N√∫mero y fecha de registro\"))\n",
    "print(f\"Bloques con 'N√∫mero y fecha de registro' encontrados: {len(textos_registro)}\")\n",
    "\n",
    "# Contexto HTML para entender la estructura\n",
    "if textos_registro:\n",
    "    # Subimos al elemento padre para ver el bloque completo\n",
    "    bloque = textos_registro[0].find_parent(\"div\") or textos_registro[0].parent\n",
    "    print(\"\\nEstructura del primer bloque:\")\n",
    "    print(bloque.prettify()[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Extraer los datos de cada entidad\n",
    "\n",
    "Ahora que conocemos la estructura, vamos a extraer los datos de forma sistem√°tica.\n",
    "\n",
    "> **Nota:** Las webs institucionales pueden cambiar su estructura HTML sin aviso. Si los selectores no funcionan, habr√° que inspeccionarla de nuevo. Esto es parte de la realidad del scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos el texto completo del contenido principal\n",
    "texto_completo = main.get_text(separator=\"\\n\")\n",
    "\n",
    "# Usamos expresiones regulares para capturar los patrones de datos\n",
    "# Patr√≥n: l√≠neas con \"N√∫mero y fecha de registro oficial: NUM - DD/MM/AAAA\"\n",
    "patron_registro = re.compile(\n",
    "    r\"N√∫mero y fecha de registro oficial:\\s*(\\d+)\\s*-\\s*(\\d{2}/\\d{2}/\\d{4})\"\n",
    ")\n",
    "\n",
    "# Patr√≥n: l√≠neas con \"Direcci√≥n: ...\"\n",
    "patron_direccion = re.compile(\n",
    "    r\"Direcci√≥n:\\s*(.+)\"\n",
    ")\n",
    "\n",
    "registros = patron_registro.findall(texto_completo)\n",
    "direcciones = patron_direccion.findall(texto_completo)\n",
    "\n",
    "print(f\"Registros encontrados: {len(registros)}\")\n",
    "print(f\"Direcciones encontradas: {len(direcciones)}\")\n",
    "\n",
    "# Mostramos los primeros 3\n",
    "for num, fecha in registros[:3]:\n",
    "    print(f\"  N¬∫ {num} - Fecha: {fecha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora extraemos los nombres de las entidades\n",
    "# Los nombres aparecen justo ANTES de cada \"N√∫mero y fecha de registro\"\n",
    "# Dividimos el texto por ese patr√≥n y cogemos la l√≠nea anterior\n",
    "\n",
    "lineas = texto_completo.split(\"\\n\")\n",
    "lineas = [l.strip() for l in lineas if l.strip()]  # Limpiamos vac√≠as\n",
    "\n",
    "entidades = []\n",
    "for i, linea in enumerate(lineas):\n",
    "    match = patron_registro.search(linea)\n",
    "    if match:\n",
    "        # El nombre de la entidad suele estar en la l√≠nea anterior\n",
    "        nombre = lineas[i - 1] if i > 0 else \"Desconocido\"\n",
    "        num_registro = match.group(1)\n",
    "        fecha_registro = match.group(2)\n",
    "        \n",
    "        # La direcci√≥n suele estar en la l√≠nea siguiente\n",
    "        direccion = \"\"\n",
    "        if i + 1 < len(lineas):\n",
    "            match_dir = patron_direccion.search(lineas[i + 1])\n",
    "            if match_dir:\n",
    "                direccion = match_dir.group(1).strip()\n",
    "        \n",
    "        entidades.append({\n",
    "            \"nombre\": nombre,\n",
    "            \"num_registro\": int(num_registro),\n",
    "            \"fecha_registro\": fecha_registro,\n",
    "            \"direccion\": direccion,\n",
    "        })\n",
    "\n",
    "print(f\"{len(entidades)} entidades extra√≠das\")\n",
    "print(\"\\nPrimeras 3:\")\n",
    "for e in entidades[:3]:\n",
    "    print(f\"  {e['nombre']} (Reg. {e['num_registro']}, {e['fecha_registro']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnmv = pd.DataFrame(entidades)\n",
    "df_cnmv[\"fecha_registro\"] = pd.to_datetime(df_cnmv[\"fecha_registro\"], format=\"%d/%m/%Y\")\n",
    "df_cnmv = df_cnmv.sort_values(\"fecha_registro\", ascending=False).reset_index(drop=True)\n",
    "df_cnmv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 An√°lisis r√°pido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¬øCu√°ntas entidades se registraron por a√±o?\n",
    "df_cnmv[\"anyo\"] = df_cnmv[\"fecha_registro\"].dt.year\n",
    "print(\"Entidades registradas por a√±o (√∫ltimos 10):\")\n",
    "print(df_cnmv[\"anyo\"].value_counts().sort_index(ascending=True).tail(10).to_string())\n",
    "\n",
    "# ¬øEn qu√© ciudades est√°n?\n",
    "# La direcci√≥n suele terminar en \"C√ìDIGO CIUDAD\", extraemos la ciudad\n",
    "df_cnmv[\"ciudad\"] = df_cnmv[\"direccion\"].str.extract(r\"\\d{5}\\s+(.+)$\")[0]\n",
    "print(\"\\nTop 5 ciudades:\")\n",
    "print(df_cnmv[\"ciudad\"].value_counts().head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Descargar un informe p√∫blico\n",
    "\n",
    "Vamos a trabajar con informes reales y p√∫blicos. Usaremos:\n",
    "- **Iberdrola** ‚Äî Informe de Gases de Efecto Invernadero 2023\n",
    "- **Iberdrola** ‚Äî Indicadores clave de sostenibilidad 2023\n",
    "\n",
    "> üí° Estos PDFs son p√∫blicos y est√°n enlazados desde la web oficial de Iberdrola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs directas a los PDFs p√∫blicos de Iberdrola\n",
    "pdfs = {\n",
    "    \"iberdrola_gei\": \"https://www.iberdrola.com/documents/20125/41101/informe-gei-2023.pdf\",\n",
    "    \"iberdrola_indicadores\": \"https://www.iberdrola.com/documents/20125/3643974/informe-integrado-esg-2023-indicadores-clave-sostenibilidad.pdf\",\n",
    "}\n",
    "\n",
    "# Creamos una carpeta para guardar los PDFs\n",
    "os.makedirs(\"pdfs_sostenibilidad\", exist_ok=True)\n",
    "\n",
    "# Descargamos cada PDF\n",
    "for nombre, url in pdfs.items():\n",
    "    ruta = f\"pdfs_sostenibilidad/{nombre}.pdf\"\n",
    "    \n",
    "    if os.path.exists(ruta):\n",
    "        print(f\"  ‚úì {nombre}.pdf ya existe, saltando descarga\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"  Descargando {nombre}...\", end=\" \")\n",
    "    resp = requests.get(url, headers=headers, timeout=60)\n",
    "    \n",
    "    if resp.status_code == 200 and resp.headers.get(\"Content-Type\", \"\").startswith(\"application/pdf\"):\n",
    "        with open(ruta, \"wb\") as f:\n",
    "            f.write(resp.content)\n",
    "        print(f\"OK ({len(resp.content)/1024:.0f} KB)\")\n",
    "    else:\n",
    "        print(f\"ERROR (status {resp.status_code})\")\n",
    "\n",
    "# Verificamos qu√© tenemos\n",
    "for f in os.listdir(\"pdfs_sostenibilidad\"):\n",
    "    size = os.path.getsize(f\"pdfs_sostenibilidad/{f}\") / 1024\n",
    "    print(f\"  üìÑ {f} ({size:.0f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Explorar la estructura de un PDF\n",
    "\n",
    "Antes de extraer datos, vamos a explorar qu√© contiene el PDF: n√∫mero de p√°ginas, texto y tablas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrimos el informe GEI de Iberdrola\n",
    "pdf = pdfplumber.open(\"pdfs_sostenibilidad/iberdrola_gei.pdf\")\n",
    "\n",
    "print(f\"N√∫mero de p√°ginas: {len(pdf.pages)}\")\n",
    "print(f\"\\n--- Texto de la primera p√°gina (primeros 500 caracteres) ---\\n\")\n",
    "texto_p1 = pdf.pages[0].extract_text()\n",
    "print(texto_p1[:500] if texto_p1 else \"(sin texto extra√≠ble en esta p√°gina)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscamos tablas en todas las p√°ginas\n",
    "print(\"Tablas encontradas por p√°gina:\")\n",
    "total_tablas = 0\n",
    "\n",
    "for i, pagina in enumerate(pdf.pages):\n",
    "    tablas = pagina.extract_tables()\n",
    "    if tablas:\n",
    "        total_tablas += len(tablas)\n",
    "        for j, tabla in enumerate(tablas):\n",
    "            print(f\"  P√°gina {i+1}, Tabla {j+1}: {len(tabla)} filas x {len(tabla[0])} columnas\")\n",
    "\n",
    "print(f\"\\nTotal de tablas: {total_tablas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Extraer tablas y convertirlas a DataFrames\n",
    "\n",
    "`pdfplumber` devuelve las tablas como listas de listas. Podemos convertirlas directamente a DataFrames de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos TODAS las tablas del PDF en una lista de DataFrames\n",
    "todos_los_dfs = []\n",
    "\n",
    "for i, pagina in enumerate(pdf.pages):\n",
    "    tablas = pagina.extract_tables()\n",
    "    for j, tabla in enumerate(tablas):\n",
    "        # La primera fila suele ser la cabecera\n",
    "        if len(tabla) > 1:\n",
    "            df_tabla = pd.DataFrame(tabla[1:], columns=tabla[0])\n",
    "            df_tabla.attrs[\"fuente\"] = f\"P√°gina {i+1}, Tabla {j+1}\"\n",
    "            todos_los_dfs.append(df_tabla)\n",
    "\n",
    "print(f\"DataFrames creados: {len(todos_los_dfs)}\")\n",
    "\n",
    "# Mostramos el primero como ejemplo\n",
    "if todos_los_dfs:\n",
    "    print(f\"\\nPrimer DataFrame ({todos_los_dfs[0].attrs.get('fuente', '')}):\")\n",
    "    display(todos_los_dfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Buscar indicadores concretos en el texto del PDF\n",
    "\n",
    "A veces los datos no est√°n en tablas limpias, sino dispersos en el texto. Podemos usar **expresiones regulares** para buscar indicadores concretos.\n",
    "\n",
    "Los informes de sostenibilidad suelen usar patrones como:\n",
    "- `\"emisiones de CO2: 125.430 tCO2eq\"`\n",
    "- `\"Alcance 1: 118.200 toneladas\"`\n",
    "- `\"43.175 MW verdes instalados\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos TODO el texto del PDF (todas las p√°ginas)\n",
    "pdf = pdfplumber.open(\"pdfs_sostenibilidad/iberdrola_gei.pdf\")\n",
    "\n",
    "texto_completo = \"\"\n",
    "for pagina in pdf.pages:\n",
    "    texto = pagina.extract_text()\n",
    "    if texto:\n",
    "        texto_completo += texto + \"\\n\"\n",
    "\n",
    "pdf.close()\n",
    "\n",
    "print(f\"Texto total extra√≠do: {len(texto_completo):,} caracteres\")\n",
    "print(f\"Palabras aproximadas: {len(texto_completo.split()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos patrones de b√∫squeda para indicadores ESG comunes\n",
    "# Cada patr√≥n captura el n√∫mero asociado al indicador\n",
    "\n",
    "patrones_esg = {\n",
    "    \"Emisiones CO2 (tCO2)\": r\"([\\d.,]+)\\s*(?:t\\s*CO2|tCO2eq|toneladas? de CO)\",\n",
    "    \"Alcance 1\": r\"[Aa]lcance\\s*1[^\\d]{0,30}([\\d.,]+)\",\n",
    "    \"Alcance 2\": r\"[Aa]lcance\\s*2[^\\d]{0,30}([\\d.,]+)\",\n",
    "    \"Alcance 3\": r\"[Aa]lcance\\s*3[^\\d]{0,30}([\\d.,]+)\",\n",
    "    \"MW instalados\": r\"([\\d.,]+)\\s*MW\",\n",
    "    \"GWh producidos\": r\"([\\d.,]+)\\s*GWh\",\n",
    "    \"Intensidad emisiones (gCO2/kWh)\": r\"([\\d.,]+)\\s*g\\s*CO2/kWh\",\n",
    "}\n",
    "\n",
    "print(\"Indicadores encontrados en el texto:\\n\")\n",
    "for indicador, patron in patrones_esg.items():\n",
    "    coincidencias = re.findall(patron, texto_completo)\n",
    "    if coincidencias:\n",
    "        # Mostramos los primeros 3 valores encontrados\n",
    "        valores = coincidencias[:3]\n",
    "        print(f\"  üìä {indicador}: {', '.join(valores)}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {indicador}: no encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 B√∫squeda contextual: obtener la l√≠nea completa\n",
    "\n",
    "A veces queremos ver no solo el n√∫mero, sino el contexto. Esto ayuda a interpretar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscamos l√≠neas que mencionen conceptos clave de sostenibilidad\n",
    "conceptos = [\"emisiones\", \"renovable\", \"CO2\", \"alcance\", \"residuo\", \"biodiversidad\"]\n",
    "\n",
    "lineas = texto_completo.split(\"\\n\")\n",
    "\n",
    "for concepto in conceptos:\n",
    "    lineas_encontradas = [l.strip() for l in lineas if concepto.lower() in l.lower()]\n",
    "    print(f\"\\nüîç '{concepto}' ‚Üí {len(lineas_encontradas)} l√≠neas\")\n",
    "    for linea in lineas_encontradas[:2]:  # Solo las 2 primeras\n",
    "        print(f\"   {linea[:120]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Comparar indicadores entre informes\n",
    "\n",
    "La verdadera potencia de la extracci√≥n de PDFs aparece cuando comparamos **el mismo indicador entre diferentes informes** (diferentes empresas o diferentes a√±os).\n",
    "\n",
    "Vamos a crear un extractor gen√©rico que funcione con cualquier informe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractor gen√©rico: dado un PDF, busca todos los indicadores ESG\n",
    "\n",
    "INDICADORES = {\n",
    "    \"emisiones_co2_total\": r\"emisiones.*?([\\d]+[.,]?\\d*)\\s*(?:millones|Mt|MtCO2)\",\n",
    "    \"alcance_1\": r\"[Aa]lcance\\s*1[^\\d]{0,40}?([\\d]+[.,]?\\d*)\",\n",
    "    \"alcance_2\": r\"[Aa]lcance\\s*2[^\\d]{0,40}?([\\d]+[.,]?\\d*)\",\n",
    "    \"mw_renovable\": r\"([\\d]+[.,]?\\d*)\\s*MW\\s*(?:renovable|verde|limpi|instalad)\",\n",
    "    \"produccion_gwh\": r\"producci√≥n.*?([\\d]+[.,]?\\d*)\\s*GWh\",\n",
    "    \"intensidad_co2\": r\"([\\d]+[.,]?\\d*)\\s*g\\s*CO2/kWh\",\n",
    "    \"empleados\": r\"(?:plantilla|empleados?|trabajadores?).*?([\\d]+[.,]?\\d*)\",\n",
    "    \"pct_mujeres\": r\"(?:mujeres|mujer|femenin).*?([\\d]+[.,]?\\d*)\\s*%\",\n",
    "}\n",
    "\n",
    "\n",
    "# Extraemos texto de un PDF y buscamos indicadores\n",
    "ruta_pdf = \"pdfs_sostenibilidad/iberdrola_gei.pdf\"\n",
    "\n",
    "pdf = pdfplumber.open(ruta_pdf)\n",
    "texto = \"\\n\".join(p.extract_text() or \"\" for p in pdf.pages)\n",
    "pdf.close()\n",
    "\n",
    "resultados = {}\n",
    "for nombre_ind, patron in INDICADORES.items():\n",
    "    match = re.search(patron, texto, re.IGNORECASE)\n",
    "    if match:\n",
    "        resultados[nombre_ind] = match.group(1)\n",
    "\n",
    "print(\"Indicadores extra√≠dos de Iberdrola GEI 2023:\")\n",
    "for k, v in resultados.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si tuvi√©ramos varios informes (ej: Iberdrola, Telef√≥nica, Endesa...)\n",
    "# har√≠amos lo mismo para cada uno y crear√≠amos un DataFrame comparativo:\n",
    "\n",
    "# Ejemplo de c√≥mo quedar√≠a con datos de varias empresas\n",
    "datos_comparativa = {\n",
    "    \"empresa\": [\"Iberdrola\", \"Telef√≥nica\", \"Endesa\"],\n",
    "    \"emisiones_scope1_tco2\": [\"extra√≠do PDF\", \"extra√≠do PDF\", \"extra√≠do PDF\"],\n",
    "    \"emisiones_scope2_tco2\": [\"extra√≠do PDF\", \"extra√≠do PDF\", \"extra√≠do PDF\"],\n",
    "    \"pct_energia_renovable\": [\"extra√≠do PDF\", \"extra√≠do PDF\", \"extra√≠do PDF\"],\n",
    "    \"mw_renovables\": [\"extra√≠do PDF\", \"extra√≠do PDF\", \"extra√≠do PDF\"],\n",
    "}\n",
    "\n",
    "print(\"Estructura del DataFrame comparativo (esquema):\")\n",
    "print(pd.DataFrame(datos_comparativa).to_string(index=False))\n",
    "print(\"\\n‚Üí Cada celda se rellenar√≠a con los valores reales extra√≠dos de cada PDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Extraer tablas de un informe de indicadores\n",
    "\n",
    "El segundo PDF (indicadores clave) es m√°s compacto y tiene tablas con datos num√©ricos concretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrimos el PDF de indicadores clave\n",
    "ruta_indicadores = \"pdfs_sostenibilidad/iberdrola_indicadores.pdf\"\n",
    "\n",
    "if os.path.exists(ruta_indicadores):\n",
    "    pdf2 = pdfplumber.open(ruta_indicadores)\n",
    "    print(f\"P√°ginas: {len(pdf2.pages)}\")\n",
    "    \n",
    "    # Extraemos todas las tablas\n",
    "    tablas_indicadores = []\n",
    "    for i, pag in enumerate(pdf2.pages):\n",
    "        for tabla in pag.extract_tables():\n",
    "            if len(tabla) > 1:  # Al menos cabecera + 1 fila\n",
    "                df = pd.DataFrame(tabla[1:], columns=tabla[0])\n",
    "                df[\"pagina\"] = i + 1\n",
    "                tablas_indicadores.append(df)\n",
    "                print(f\"  P√°g {i+1}: tabla de {len(tabla)-1} filas x {len(tabla[0])} cols\")\n",
    "    \n",
    "    pdf2.close()\n",
    "    \n",
    "    # Mostramos la primera tabla extra√≠da\n",
    "    if tablas_indicadores:\n",
    "        print(\"\\nPrimera tabla:\")\n",
    "        display(tablas_indicadores[0])\n",
    "else:\n",
    "    print(f\"Archivo no encontrado: {ruta_indicadores}\")\n",
    "    print(\"Puede que la descarga haya fallado. Verifica la URL manualmente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
